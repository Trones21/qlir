# __PROJECT_NAME__

üöÄ **QLIR Quickstart Scaffold**

This is a starter layout for a project that will use the QLIR library.

## ‚öôÔ∏è Setup

0. Clone qlir if using local dep (the ironic thing is that to use quickstart.py you already cloned, so you just need the path that you cloned to)
1. Update the QLIR dependency in `pyproject.toml` before running install.

```toml
  # Local path dependency (edit as needed)
  # "qlir @ file:///<absolute_path_to_cloned_qlir>/qlir",

  # Or use the Git version:
  # "qlir @ git+https://github.com/Trones21/qlir.git@main",
````

`See the py.project.toml for instructions on how to use an editable version of qlir, this requires some python/poetry knowledge and is not recommended for beginners`

3. Install dependencies and run:

```bash
poetry install
poetry run analysis
# or
poetry run python -m __PROJECT_NAME__.main
```

## üß© Project Structure

```text
__PROJECT_NAME__/
  README.md
  pyproject.toml
  src/__PROJECT_NAME__/
    __init__.py
    main.py
  tests/
  outputs/
  data/
```

* `src/__PROJECT_NAME__/main.py` ‚Äî entry point for your analysis
* `data/` ‚Äî optional local inputs
* `outputs/` ‚Äî generated tables, plots, and artifacts
* `tests/` ‚Äî smoke tests, regression tests, etc.

## üì¶ QLIR Data Storage Philosophy

QLIR is designed around a **canonical, disk-first data model**.

### 1. Canonical on-disk layout

By default, QLIR expects candle data under a root like:

```text
~/qlir_data/<datasource>/<instrument>_<resolution>.parquet
```

You can override the root directory, but the structure remains the same.

QLIR standardizes:

* instrument identifiers
* resolution strings
* filename conventions
* metadata schemas

This provides a stable **data identity layer**.

### 2. Disk ‚Üí network workflow

Every pipeline should obtain candles via a loader such as:

```python
get_candles(instrument, resolution, datasource)
```

Conceptually, QLIR will:

1. Compute the canonical path
2. If the file exists on disk ‚Üí load it immediately
3. If not ‚Üí fetch from the network, normalize, and return it
4. Optionally persist the result via the I/O layer

This gives you reproducibility, speed, and deterministic behavior.

### 3. Store canonical 1-minute candles

The intended pattern is:

* store **1m candles** per instrument + datasource on disk
* resample to higher timeframes (5m, 15m, 1h, etc.) in-memory
* only cache higher-res datasets if runtime actually becomes a bottleneck

This avoids an explosion of redundant files while keeping resampling flexible.

### 4. Updating datasets on disk

Typical study pipelines include an explicit update step, e.g.:

```python
def update_disk_dataset():
    """Fetch new candles, merge with existing data, and write back to disk."""
    ...
```

You can call this from your study, or maintain separate updater scripts/CLIs
that keep your canonical datasets fresh.

Once the canonical data exists on disk, your studies can repeatedly:

* load from disk
* resample
* enrich
* run edge / strategy logic

without re-fetching full history each run.

## üìä Data & Outputs

When your workflow produces files under `outputs/`, consider including **metadata** about the dataset or parameters that generated them.

Good practice:

* Add an `outputs/README.md` describing the data source and run context.
* If the underlying dataset is too large or private to check in, add a checksum or manifest.
* For large binary artifacts, consider using Git LFS and track only pointers.

If someone sees an output in your repo, they should be able to tell *what data and settings produced it*.

## üí¨ Next Steps

* Use this scaffold as a starting point for a single study.
* Gradually extract reusable pieces into shared modules.
* Explore QLIR examples (if present) for patterns and conventions.
